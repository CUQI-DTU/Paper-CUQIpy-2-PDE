{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for CUQIpy paper 2, section 4. CUQIpy-FEniCS example: Electrical Impedance Tomography (EIT)\n",
    "\n",
    "**Note: The exact paper figures are shown at the very end of this notebook.**\n",
    "\n",
    "This notebook demonstrates setting up an Electrical Impedance Tomography (EIT) problem in `CUQIpy`. It uses the plug-in `CUQIpy-FEniCS` to solve the forward problem and interface with `CUQIpy` Bayesian modeling and sampling tools. We are after inferring the conductivity field in a 2D domain from boundary current measurements. The notebook demonstrates creating the PDE forward model, prior, likelihood, and posterior. We also demonstrate sampling using `CUQIpy` and visualize the results. Here we parametrize the prior using a combination of KL expansion and level-set parameterization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import required libraries and classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T15:59:36.576871Z",
     "iopub.status.busy": "2024-02-22T15:59:36.576411Z",
     "iopub.status.idle": "2024-02-22T15:59:42.268758Z",
     "shell.execute_reply": "2024-02-22T15:59:42.268158Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dolfin as dl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cuqi\n",
    "import cuqipy_fenics\n",
    "from cuqi.geometry import Continuous1D\n",
    "from cuqi.model import PDEModel\n",
    "from cuqi.distribution import Gaussian, JointDistribution\n",
    "from cuqi.samples import Samples\n",
    "from cuqi.sampler import MH\n",
    "from cuqipy_fenics.geometry import FEniCSContinuous, MaternKLExpansion,\\\n",
    "                                   FEniCSMappedGeometry \n",
    "from cuqipy_fenics.pde import SteadyStateLinearFEniCSPDE\n",
    "from figures_util import plot_figure6, plot_figure7, plot_figure8, plot_figure9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print CUQIpy and CUQIpy-FEniCS versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T15:59:42.273993Z",
     "iopub.status.busy": "2024-02-22T15:59:42.273533Z",
     "iopub.status.idle": "2024-02-22T15:59:42.278895Z",
     "shell.execute_reply": "2024-02-22T15:59:42.278109Z"
    }
   },
   "outputs": [],
   "source": [
    "print(cuqi.__version__)\n",
    "print(cuqipy_fenics.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a helper function `extract_boundary_dofs_indices` to extract the indices of the boundary degrees of freedom (dofs) of a FEniCS function space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T15:59:42.332652Z",
     "iopub.status.busy": "2024-02-22T15:59:42.332259Z",
     "iopub.status.idle": "2024-02-22T15:59:42.338922Z",
     "shell.execute_reply": "2024-02-22T15:59:42.338062Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function for extracting the indices of the boundary nodes\n",
    "def extract_boundary_dofs_indices(solution_space):\n",
    "\n",
    "    v0 = dl.Constant('0.0')\n",
    "    boundary = lambda x, on_boundary: on_boundary\n",
    "    zero_bc = dl.DirichletBC(solution_space, v0, boundary)\n",
    "    dummy = dl.Function(solution_space)\n",
    "    dummy.vector().set_local(np.ones_like(dummy.vector().get_local()))\n",
    "    zero_bc.apply(dummy.vector())\n",
    "    bnd_idx = np.argwhere(\n",
    "        dummy.vector().get_local()==0).flatten() # this holds the indecies of\n",
    "                                                 # the boundary elements\n",
    "    return bnd_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function `create_domain_geometry` that creates the domain geometry of the EIT problem that defines the KL and level-set parameterization of the prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T15:59:42.342527Z",
     "iopub.status.busy": "2024-02-22T15:59:42.342146Z",
     "iopub.status.idle": "2024-02-22T15:59:42.347392Z",
     "shell.execute_reply": "2024-02-22T15:59:42.346868Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_domain_geometry(parameter_space, bnd_idx):\n",
    "    # The geometry on which the Bayesian parameters are defined corresponds to\n",
    "    # the FEM parameterization\n",
    "    G_FEM = FEniCSContinuous(parameter_space)\n",
    "    \n",
    "    # The KL parameterization\n",
    "    G_KL = MaternKLExpansion(G_FEM, length_scale=0.2, num_terms=64)\n",
    "    \n",
    "    # Defining the Heaviside map\n",
    "    c_minus = 1\n",
    "    c_plus = 10\n",
    "    def Heaviside(func):\n",
    "        dofs = \\\n",
    "            func.vector().get_local() # extracting the function values at FEM \n",
    "                                      # nodes (this only works for linear \n",
    "                                      # element)\n",
    "        updated_dofs = c_minus*0.5*(1 + np.sign(dofs))+\\\n",
    "                       c_plus*0.5*(1 - np.sign(dofs))\n",
    "    \n",
    "        # Here we insure that the boundary values of the conductivity is \n",
    "        # always one\n",
    "        updated_dofs[bnd_idx] = np.ones_like(bnd_idx)\n",
    "        func.vector().set_local(updated_dofs)\n",
    "        return func\n",
    "    \n",
    "    # creating the domain geometry which applies the map Heaviside map to G_KL \n",
    "    # realizations.\n",
    "    G_Heavi = FEniCSMappedGeometry(G_KL, map=Heaviside)\n",
    "    return G_Heavi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function `run_EIT` that, for a given noise level of the data, reads the noisy data from folder `data`, sets up the EIT Bayesian inverse problem, samples the posterior, and visualizes and saves the results. The results are saved in a folder named `stat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T15:59:42.350808Z",
     "iopub.status.busy": "2024-02-22T15:59:42.350565Z",
     "iopub.status.idle": "2024-02-22T15:59:42.371715Z",
     "shell.execute_reply": "2024-02-22T15:59:42.371058Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_EIT(noise_percent, Ns=1000000, Nb=200000, Nt=4000, seed=2):\n",
    "    \"\"\"Main function for running the EIT example. Inputs are the noise\n",
    "    percentage (`noise_percent`), the number of samples (`Ns`), the number of\n",
    "    burn-in samples (`Nb`), the number of thinning samples (Nt), and the random\n",
    "    seed (`seed`). The function saves the results in a folder `stat`\"\"\"\n",
    "    # Fix the random seed for reproducibility \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    #%% 1 setting up FEniCS\n",
    "    # loading computational mesh\n",
    "    mesh = dl.Mesh(\"mesh.xml\")\n",
    "    \n",
    "    #%% 1.1 Define function spaces \n",
    "    parameter_space = dl.FunctionSpace(mesh, \"CG\", 1)\n",
    "    solution_space = dl.FunctionSpace(mesh, \"CG\", 1)\n",
    "    \n",
    "    #%% 1.2 defining the lifted weak formulation\n",
    "    \n",
    "    # Function that marks the boundary of the computational mesh\n",
    "    boundary = lambda x, on_boundary: on_boundary\n",
    "    \n",
    "    # Creating lhs form\n",
    "    form_lhs = lambda sigma, v, t: dl.inner(sigma*dl.grad(v), dl.grad(t))*dl.dx\n",
    "    \n",
    "    # Creating rhs for frequencies k=1,2,3,4\n",
    "    # Creating the boundary condition expression and DirichletBC to be used\n",
    "    # in building the rhs (using lifting).\n",
    "    boundary_expression = dl.Expression(\n",
    "        \"sin(k*atan2(x[1], x[0]))\", k=1, degree=1)\n",
    "    bc = dl.DirichletBC(solution_space,\n",
    "                        boundary_expression,\n",
    "                        boundary) # applying this boundary condition on a\n",
    "                                  # function will create u_lift for the \n",
    "                                  # frequency in bc_func\n",
    "    \n",
    "    # creating functions for the boundary condition u_lift_1, u_lift_2,\n",
    "    # u_lift_3, u_lift_4\n",
    "    boundary_expression.k = 1 # setting the frequency\n",
    "    u_lift_1 = dl.Function(solution_space)\n",
    "    bc.apply(u_lift_1.vector())\n",
    "    \n",
    "    boundary_expression.k = 2 # setting the frequency\n",
    "    u_lift_2 = dl.Function(solution_space)\n",
    "    bc.apply(u_lift_2.vector())\n",
    "    \n",
    "    boundary_expression.k = 3 # setting the frequency\n",
    "    u_lift_3 = dl.Function(solution_space)\n",
    "    bc.apply(u_lift_3.vector())\n",
    "    \n",
    "    boundary_expression.k = 4 # setting the frequency\n",
    "    u_lift_4 = dl.Function(solution_space)\n",
    "    bc.apply(u_lift_4.vector())\n",
    "    \n",
    "    # creating rhs forms\n",
    "    form_rhs1 = lambda sigma, t: -dl.inner(dl.grad(u_lift_1), dl.grad(t))*dl.dx\n",
    "    form_rhs2 = lambda sigma, t: -dl.inner(dl.grad(u_lift_2), dl.grad(t))*dl.dx\n",
    "    form_rhs3 = lambda sigma, t: -dl.inner(dl.grad(u_lift_3), dl.grad(t))*dl.dx\n",
    "    form_rhs4 = lambda sigma, t: -dl.inner(dl.grad(u_lift_4), dl.grad(t))*dl.dx\n",
    "    \n",
    "    #%% 1.3 defining the observation function\n",
    "    # Defining zero boundary for the lifted problem\n",
    "    v0 = dl.Constant('0.0')\n",
    "    zero_bc = dl.DirichletBC(solution_space, v0, boundary)\n",
    "    # extracting indices for elements at the boundary of the computational mesh\n",
    "    bnd_idx = extract_boundary_dofs_indices(solution_space)\n",
    "    \n",
    "    # defining normal vectors to the cell boundaries\n",
    "    n = dl.FacetNormal( mesh )\n",
    "    # defining FEniCS test functions\n",
    "    w = dl.TestFunction( solution_space )\n",
    "    \n",
    "    # defining a function that returns the values at the boundaries\n",
    "    def give_bnd_vals(obs_form):\n",
    "        return obs_form.get_local()[bnd_idx]\n",
    "    \n",
    "    # defining the observation functions\n",
    "    def observation1(sigma, v1):\n",
    "        obs_form = dl.inner(dl.grad(v1 + u_lift_1), n)*w*dl.ds\n",
    "        assembled_form = dl.assemble(obs_form)\n",
    "        boundary_values = give_bnd_vals(assembled_form)\n",
    "        return boundary_values\n",
    "    \n",
    "    def observation2(sigma, v2):\n",
    "        obs_form = dl.inner(dl.grad(v2 + u_lift_2), n)*w*dl.ds\n",
    "        assembled_form = dl.assemble(obs_form)\n",
    "        boundary_values = give_bnd_vals(assembled_form)\n",
    "        return boundary_values\n",
    "    \n",
    "    def observation3(sigma, v3):\n",
    "        obs_form = dl.inner(dl.grad(v3 + u_lift_3), n)*w*dl.ds\n",
    "        assembled_form = dl.assemble(obs_form)\n",
    "        boundary_values = give_bnd_vals(assembled_form)\n",
    "        return boundary_values\n",
    "    \n",
    "    def observation4(sigma, v4):\n",
    "        obs_form = dl.inner(dl.grad(v4 + u_lift_4), n)*w*dl.ds\n",
    "        assembled_form = dl.assemble(obs_form)\n",
    "        boundary_values = give_bnd_vals(assembled_form)\n",
    "        return boundary_values\n",
    "    \n",
    "    #%% 2 parameterization and geometries\n",
    "    # Create the domain geometry\n",
    "    G_Heavi = create_domain_geometry(parameter_space, bnd_idx)\n",
    "\n",
    "    #%% 3 Creating the prior distribution\n",
    "    # Create the range geometry \n",
    "    m = len(bnd_idx)\n",
    "    G_cont = Continuous1D(m)\n",
    "    \n",
    "    # Create a prior\n",
    "    n_KL = G_Heavi.par_dim\n",
    "    x = Gaussian(np.zeros(n_KL), 1, geometry=G_Heavi)\n",
    "    \n",
    "    #%% 4 Creating the posterior distribution\n",
    "    # loading signal from file\n",
    "    obs_data = np.load('./data/obs_circular_inclusion_2_'+str(noise_percent)+'per_noise.npz')\n",
    "    b_exact = obs_data['b_exact']\n",
    "    s_noise_list = np.sqrt(obs_data['sigma2']) # read the noise variance and\n",
    "                                               # convert to std\n",
    "    \n",
    "    data = obs_data['data']\n",
    "    y1_obs = data[0]\n",
    "    y2_obs = data[1]\n",
    "    y3_obs = data[2]\n",
    "    y4_obs = data[3]\n",
    "    \n",
    "    # creating PDE forms\n",
    "    PDE_form1 = (form_lhs, form_rhs1)\n",
    "    \n",
    "    # creating PDE models\n",
    "    # for the first PDE problems we specify to reuse the factorization of the \n",
    "    # lhs for the rest of the PDE models\n",
    "    PDE1 = SteadyStateLinearFEniCSPDE(\n",
    "        PDE_form1,\n",
    "        mesh,\n",
    "        solution_space,\n",
    "        parameter_space,\n",
    "        zero_bc,\n",
    "        observation_operator=observation1,\n",
    "        reuse_assembled=True)\n",
    "    \n",
    "    # We copy the PDE1 for the rest of the PDE problems with updated rhs\n",
    "    PDE2 = PDE1.with_updated_rhs(form_rhs2)\n",
    "    PDE2.observation_operator = observation2\n",
    "    PDE3 = PDE1.with_updated_rhs(form_rhs3)\n",
    "    PDE3.observation_operator = observation3\n",
    "    PDE4 = PDE1.with_updated_rhs(form_rhs4)\n",
    "    PDE4.observation_operator = observation4\n",
    "    \n",
    "    # Creating the forward operators\n",
    "    A1 = PDEModel(PDE1, range_geometry=G_cont, domain_geometry=G_Heavi)\n",
    "    A2 = PDEModel(PDE2, range_geometry=G_cont, domain_geometry=G_Heavi)\n",
    "    A3 = PDEModel(PDE3, range_geometry=G_cont, domain_geometry=G_Heavi)\n",
    "    A4 = PDEModel(PDE4, range_geometry=G_cont, domain_geometry=G_Heavi)\n",
    "    \n",
    "    # creating data distributions\n",
    "    s_noise = s_noise_list[0]\n",
    "    y1 = Gaussian(A1(x), s_noise**2, geometry=G_cont)\n",
    "    \n",
    "    s_noise = s_noise_list[1]\n",
    "    y2 = Gaussian(A2(x), s_noise**2, geometry=G_cont)\n",
    "    \n",
    "    s_noise = s_noise_list[2]\n",
    "    y3 = Gaussian(A3(x), s_noise**2, geometry=G_cont)\n",
    "    \n",
    "    s_noise = s_noise_list[3]\n",
    "    y4 = Gaussian(A4(x), s_noise**2, geometry=G_cont)\n",
    "    \n",
    "    # Creating the joint data distribution and the joint likelihood\n",
    "    joint = JointDistribution(x, y1, y2, y3, y4)\n",
    "    posterior = joint(y1=y1_obs, y2=y2_obs, y3=y3_obs, y4=y4_obs)\n",
    "    \n",
    "    #%% 5 sampling\n",
    "    # Create Metropolis-Hastings Sampler \n",
    "    sampler = MH(posterior)\n",
    "    \n",
    "    # Sampling using the Metropolis-Hastings sampler\n",
    "    posterior_samples = sampler.sample_adapt(Ns)\n",
    "    \n",
    "    #%% 6 visualization\n",
    "    # plotting prior samples\n",
    "    f, axes = plt.subplots(1,3)\n",
    "    plt.sca(axes[0])\n",
    "    prior_sample = x.sample()\n",
    "    prior_sample.plot(subplots=False)\n",
    "    plt.sca(axes[1])\n",
    "    prior_sample = x.sample()\n",
    "    prior_sample.plot(subplots=False)\n",
    "    plt.sca(axes[2])\n",
    "    prior_sample = x.sample()\n",
    "    prior_sample.plot(subplots=False)\n",
    "    axes[1].set_title('prior samples')\n",
    "    plt.savefig(\"plot_prior_samples\"+str(noise_percent)+\".png\")\n",
    "    \n",
    "    # plotting posterior samples\n",
    "    idx = np.random.permutation(Ns) # create randomized index\n",
    "    f, axes = plt.subplots(1,3)\n",
    "    plt.sca(axes[0])\n",
    "    posterior_samples.plot(idx[0],subplots=False)\n",
    "    plt.sca(axes[1])\n",
    "    posterior_samples.plot(idx[1],subplots=False)\n",
    "    plt.sca(axes[2])\n",
    "    posterior_samples.plot(idx[2],subplots=False)\n",
    "    axes[1].set_title('posterior samples')\n",
    "    plt.savefig(\"plot_posterior_samples\"+str(noise_percent)+\".png\")\n",
    "    \n",
    "    # burn-thin the samples\n",
    "    posterior_samples = posterior_samples.burnthin(Nb, Nt)\n",
    "    \n",
    "    # plotting the mean\n",
    "    f, axes = plt.subplots(1,2)\n",
    "    plt.sca(axes[0])\n",
    "    posterior_samples.plot_mean(subplots=False)\n",
    "    axes[0].set_title('sample mean')\n",
    "    \n",
    "    # plotting the variance\n",
    "    plt.sca(axes[1])\n",
    "    posterior_samples.funvals.vector.plot_variance(subplots=False)\n",
    "    axes[1].set_title('variance')\n",
    "    plt.savefig(\"plot_mean_variance\"+str(noise_percent)+\".png\")\n",
    "    \n",
    "    # plotting the credible intervals\n",
    "    plt.figure()\n",
    "    posterior_samples.plot_ci(95, plot_par=True)\n",
    "    plt.savefig(\"plot_ci\"+str(noise_percent)+\".png\")\n",
    "    \n",
    "    # Create directory for saving the results if it does not exist\n",
    "    if not os.path.exists('./stat'):\n",
    "        os.makedirs('./stat')\n",
    "\n",
    "    # Save the posterior samples\n",
    "    np.savez(\"./stat/stat_circular_inclusion_2_\"\n",
    "             +str(noise_percent)+\"per_noise_thinned.npz\",\n",
    "             samples=posterior_samples.samples)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each noise level, we call `run_EIT` to solve the Bayesian EIT problem and save the results. This could take about 5 hours to run for each noise level. You can set `Ns`, the number of samples, to a smaller value to get results quicker for a shorter MCMC chain. Note that you will also need to set the burn-in `Nb` and the thinning `Nt` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T15:59:42.375412Z",
     "iopub.status.busy": "2024-02-22T15:59:42.375169Z",
     "iopub.status.idle": "2024-02-22T16:00:03.854222Z",
     "shell.execute_reply": "2024-02-22T16:00:03.853572Z"
    }
   },
   "outputs": [],
   "source": [
    "noise_percent = 5 # 5% noise\n",
    "print(\"Running EIT for noise percent: \", noise_percent)\n",
    "run_EIT(noise_percent, Ns=1000000, Nb=200000, Nt=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T16:00:03.858840Z",
     "iopub.status.busy": "2024-02-22T16:00:03.858602Z",
     "iopub.status.idle": "2024-02-22T16:00:06.754386Z",
     "shell.execute_reply": "2024-02-22T16:00:06.753699Z"
    }
   },
   "outputs": [],
   "source": [
    "noise_percent = 10 # 10% noise\n",
    "print(\"Running EIT for noise percent: \", noise_percent)\n",
    "run_EIT(noise_percent, Ns=1000000, Nb=200000, Nt=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T16:00:06.759158Z",
     "iopub.status.busy": "2024-02-22T16:00:06.758811Z",
     "iopub.status.idle": "2024-02-22T16:00:09.664103Z",
     "shell.execute_reply": "2024-02-22T16:00:09.663447Z"
    }
   },
   "outputs": [],
   "source": [
    "noise_percent = 20 # 20% noise\n",
    "print(\"Running EIT for noise percent: \", noise_percent)\n",
    "run_EIT(noise_percent, Ns=1000000, Nb=200000, Nt=4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we run the following code cells to generate the exact paper figures from the samples generated above, these figures are saved in `plots` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up `matplotlib` parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T16:00:09.669132Z",
     "iopub.status.busy": "2024-02-22T16:00:09.668887Z",
     "iopub.status.idle": "2024-02-22T16:00:09.673770Z",
     "shell.execute_reply": "2024-02-22T16:00:09.673213Z"
    }
   },
   "outputs": [],
   "source": [
    "SMALL_SIZE = 7\n",
    "MEDIUM_SIZE = 8\n",
    "BIGGER_SIZE = 9\n",
    "plt.rc('font', size=MEDIUM_SIZE)         # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)    # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T16:00:09.677602Z",
     "iopub.status.busy": "2024-02-22T16:00:09.677336Z",
     "iopub.status.idle": "2024-02-22T16:00:09.687000Z",
     "shell.execute_reply": "2024-02-22T16:00:09.686302Z"
    }
   },
   "outputs": [],
   "source": [
    "#%% Load the sample files\n",
    "print('loading ...')\n",
    "print('data 1 ...')\n",
    "data1 = np.load('./stat/stat_circular_inclusion_2_5per_noise_thinned.npz')\n",
    "samples1 = data1['samples']\n",
    "print('data 2 ...')\n",
    "data2 = np.load('./stat/stat_circular_inclusion_2_10per_noise_thinned.npz')\n",
    "samples2 = data2['samples']\n",
    "print('data 3 ...')\n",
    "data3 = np.load('./stat/stat_circular_inclusion_2_20per_noise_thinned.npz')\n",
    "samples3 = data3['samples']\n",
    "\n",
    "#%% Load the exact conductivity and the data\n",
    "obs_data3 = np.load('./data/obs_circular_inclusion_2_20per_noise.npz')\n",
    "data = obs_data3['data']\n",
    "exact_data = obs_data3['b_exact']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the domain geometry `domain_geometry` again (for plotting purposes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T16:00:09.690547Z",
     "iopub.status.busy": "2024-02-22T16:00:09.690275Z",
     "iopub.status.idle": "2024-02-22T16:00:09.705696Z",
     "shell.execute_reply": "2024-02-22T16:00:09.705185Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load mesh\n",
    "mesh = dl.Mesh(\"mesh.xml\")\n",
    "\n",
    "# Define function spaces \n",
    "parameter_space = dl.FunctionSpace(mesh, \"CG\", 1)\n",
    "solution_space = dl.FunctionSpace(mesh, \"CG\", 1)\n",
    "\n",
    "# extracting indices for elements at the boundary of the computational mesh\n",
    "bnd_idx = extract_boundary_dofs_indices(solution_space)\n",
    "\n",
    "# Create the domain geometry\n",
    "G_Heavi = create_domain_geometry(parameter_space, bnd_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Samples objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T16:00:09.709584Z",
     "iopub.status.busy": "2024-02-22T16:00:09.709286Z",
     "iopub.status.idle": "2024-02-22T16:00:09.712621Z",
     "shell.execute_reply": "2024-02-22T16:00:09.712095Z"
    }
   },
   "outputs": [],
   "source": [
    "cuqi_samples1 = Samples(samples1, geometry=G_Heavi)\n",
    "cuqi_samples2 = Samples(samples2, geometry=G_Heavi)\n",
    "cuqi_samples3 = Samples(samples3, geometry=G_Heavi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create prior samples to be plotted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T16:00:09.716066Z",
     "iopub.status.busy": "2024-02-22T16:00:09.715787Z",
     "iopub.status.idle": "2024-02-22T16:00:09.720300Z",
     "shell.execute_reply": "2024-02-22T16:00:09.719606Z"
    }
   },
   "outputs": [],
   "source": [
    "x = Gaussian(0, 1, geometry=G_Heavi)\n",
    "prior_samples = x.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create plot directory if it does not exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T16:00:09.723531Z",
     "iopub.status.busy": "2024-02-22T16:00:09.723267Z",
     "iopub.status.idle": "2024-02-22T16:00:09.728667Z",
     "shell.execute_reply": "2024-02-22T16:00:09.727974Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('./plots'):\n",
    "    os.makedirs('./plots')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot figure 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T16:00:09.731981Z",
     "iopub.status.busy": "2024-02-22T16:00:09.731666Z",
     "iopub.status.idle": "2024-02-22T16:00:11.527123Z",
     "shell.execute_reply": "2024-02-22T16:00:11.526366Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_figure6(parameter_space, exact_data, data)\n",
    "plt.savefig('./plots/data.pdf',format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot figure 7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T16:00:11.532593Z",
     "iopub.status.busy": "2024-02-22T16:00:11.532320Z",
     "iopub.status.idle": "2024-02-22T16:00:13.509201Z",
     "shell.execute_reply": "2024-02-22T16:00:13.508534Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_figure7(prior_samples, cuqi_samples1, cuqi_samples2, cuqi_samples3,\n",
    "             prior_samples_idx_to_plot=[0, 2], \n",
    "             posterior_samples_idx_to_plot=[2, -10])\n",
    "plt.savefig('./plots/samples.pdf',format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot figure 8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T16:00:13.515078Z",
     "iopub.status.busy": "2024-02-22T16:00:13.514752Z",
     "iopub.status.idle": "2024-02-22T16:00:16.525179Z",
     "shell.execute_reply": "2024-02-22T16:00:16.524380Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_figure8(cuqi_samples1, cuqi_samples2, cuqi_samples3)\n",
    "plt.savefig('./plots/uq.pdf',format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot figure 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T16:00:16.531599Z",
     "iopub.status.busy": "2024-02-22T16:00:16.531388Z",
     "iopub.status.idle": "2024-02-22T16:00:17.453539Z",
     "shell.execute_reply": "2024-02-22T16:00:17.452648Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_figure9(cuqi_samples1, cuqi_samples2, cuqi_samples3)\n",
    "plt.savefig('./plots/params.pdf',format='pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
