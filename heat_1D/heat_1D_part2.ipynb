{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Framework for PDE-based Bayesian inverse problems in CUQIpy (section 2.7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7. Parameterizing the initial condition using Karhunenâ€“Lo`eve (KL) expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cuqi.distribution import Gaussian, JointDistribution\n",
    "from cuqi.geometry import Continuous1D, KLExpansion, StepExpansion\n",
    "from cuqi.pde import TimeDependentLinearPDE\n",
    "from cuqi.model import PDEModel\n",
    "from cuqi.sampler import CWMH\n",
    "from cuqi.array import CUQIarray\n",
    "from paper_figures import plot_figure5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code cell is repeated set up that is included in sections 2.2 to 2.6 (heat_1D_part1.ipynb). We repeat it here because we need it to set up the 1D heat-based Bayesian inverse problem cases discussed in section 2.7.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grid = 100   # Number of solution nodes\n",
    "h = 1/(n_grid+1)   # Space step size\n",
    "grid = np.linspace(h, 1-h, n_grid)\n",
    "\n",
    "tau_max = 0.01 # Final time (in sections 2.2 to 2.6, tau_max=0.02)\n",
    "cfl = 5/11 # The cfl condition to have a stable solution\n",
    "dt_approx = cfl*h**2 # Defining approximate time step size\n",
    "n_tau = int(tau_max/dt_approx)+1 # Number of time steps\n",
    "tau = np.linspace(0, tau_max, n_tau)\n",
    "\n",
    "c = 1\n",
    "f = np.zeros(n_grid)\n",
    "D_c = c**2 * ( np.diag(-2*np.ones(n_grid), 0) +\n",
    "np.diag(np.ones(n_grid-1), -1) +\n",
    "np.diag(np.ones(n_grid-1), 1) ) / h**2\n",
    "\n",
    "def PDE_form(g, tau_current):\n",
    "    return (D_c, f, g)\n",
    "\n",
    "g_custom =1/30*(1-np.cos(2*np.pi*(1-grid)/(1)))\\\n",
    "                +1/30*np.exp(-2*(10*(grid-0.5))**2)+\\\n",
    "                 1/30*np.exp(-2*(10*(grid-0.8))**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap g_custom into a CUQIarray\n",
    "g_custom = CUQIarray(g_custom, is_par=False, geometry=G_KL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KL geoemtry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_KL = KLExpansion(grid, decay_rate=1.5, normalizer=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The factor to reduce the number of samples just to make the code\n",
    "# run faster, setting it to 1 will give the same results as in the paper\n",
    "# up to some random effect due to the random sampling and noise\n",
    "Ns_factor = 0.005  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1:\n",
    "\n",
    "Note that the next code cells content was discussed in sections 2.1-2.6, here \n",
    "we make slight modification to accommodate for the first case of the three KL \n",
    "expansion cases presented in section 2.7 (the case with observation everywhere \n",
    "and 0.1% noise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDE_1 = TimeDependentLinearPDE(PDE_form, tau, grid_sol=grid)\n",
    "\n",
    "PDE_1.assemble(g_custom)\n",
    "u_custom_1, info = PDE_1.solve()\n",
    "y_custom_1 = PDE_1.observe(u_custom_1)\n",
    "\n",
    "G_cont_1 = Continuous1D(grid)\n",
    "A_case_1 = PDEModel(PDE_1, range_geometry=G_cont_1, domain_geometry=G_KL)\n",
    "\n",
    "noise_level_1 = 0.001\n",
    "s_noise_1 =1.0/np.sqrt(n_grid)* noise_level_1*np.linalg.norm(y_custom_1)\n",
    "\n",
    "x = Gaussian(np.zeros(G_KL.par_dim), 1, geometry=G_KL)\n",
    "prior_samples = x.sample(5)\n",
    "\n",
    "y_1 = Gaussian(A_case_1(x), s_noise_1**2, geometry=G_cont_1)\n",
    "\n",
    "y_obs_1 = y_1(x=g_custom).sample()\n",
    "\n",
    "joint_1 = JointDistribution(x, y_1)\n",
    "posterior_1 = joint_1(y=y_obs_1)\n",
    "\n",
    "scale_1 = np.ones(G_KL.par_dim)\n",
    "scale_1[0] = 0.5\n",
    "my_sampler_1 = CWMH(posterior_1, scale=scale_1)\n",
    "\n",
    "posterior_samples_1 = my_sampler_1.sample_adapt(int(50000*Ns_factor))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a list of case 1 data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case1_data = [g_custom, y_custom_1, y_obs_1, posterior_samples_1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2:\n",
    "\n",
    "Note that the next code cells content was discussed in sections 2.1-2.6, here \n",
    "we make slight modification to accommodate for the second case of the three KL \n",
    "expansion cases presented in section 2.7 (the case with observation everywhere \n",
    "and 5% noise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDE_2 = PDE_1\n",
    "\n",
    "y_custom_2 = y_custom_1\n",
    "\n",
    "A_case_2 = A_case_1\n",
    "\n",
    "noise_level_2 = 0.05\n",
    "s_noise_2 =1.0/np.sqrt(n_grid)* noise_level_2*np.linalg.norm(y_custom_2)\n",
    "\n",
    "y_2 = Gaussian(A_case_2(x), s_noise_2**2, geometry=A_case_2.range_geometry)\n",
    "\n",
    "y_obs_2 = y_2(x=g_custom).sample()\n",
    "\n",
    "joint_2 = JointDistribution(x, y_2)\n",
    "posterior_2 = joint_2(y=y_obs_2)\n",
    "\n",
    "scale_2 = np.ones(G_KL.par_dim)\n",
    "scale_2[0] = 0.5\n",
    "my_sampler_2 = CWMH(posterior_2, scale=scale_2)\n",
    "\n",
    "posterior_samples_2 = my_sampler_2.sample_adapt(int(50000*Ns_factor))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a list of case 2 data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case2_data = [g_custom, y_custom_2, y_obs_2, posterior_samples_2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 3:\n",
    "\n",
    "Note that the next code cells content was discussed in sections 2.1-2.6, here \n",
    "we make slight modification to accommodate for the second case of the three KL \n",
    "expansion cases presented in section 2.7 (the case with observation on the left\n",
    "half of the domain and 5% noise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDE_3 = TimeDependentLinearPDE(PDE_form, tau, grid_sol=grid, grid_obs=grid[:50])\n",
    "\n",
    "PDE_3.assemble(g_custom)\n",
    "u_custom_3, info = PDE_3.solve()\n",
    "y_custom_3 = PDE_3.observe(u_custom_3)\n",
    "\n",
    "G_cont_3 = Continuous1D(grid[:50])\n",
    "A_case_3 = PDEModel(PDE_3, range_geometry=G_cont_3, domain_geometry=G_KL)\n",
    "\n",
    "noise_level_3 = 0.05\n",
    "s_noise_3 =1.0/np.sqrt(n_grid)* noise_level_3*np.linalg.norm(y_custom_3)\n",
    "\n",
    "y_3 = Gaussian(A_case_3(x), s_noise_3**2, geometry=G_cont_3)\n",
    "\n",
    "y_obs_3 = y_3(x=g_custom).sample()\n",
    "\n",
    "joint_3 = JointDistribution(x, y_3)\n",
    "posterior_3 = joint_3(y=y_obs_3)\n",
    "\n",
    "scale_3 = np.ones(G_KL.par_dim)\n",
    "scale_3[0] = 0.5\n",
    "my_sampler_3 = CWMH(posterior_3, scale=scale_3)\n",
    "\n",
    "posterior_samples_3 = my_sampler_3.sample_adapt(int(50000*Ns_factor))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a list of case 3 data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case3_data = [g_custom, y_custom_3, y_obs_3, posterior_samples_3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code cell for plotting figure 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig_dir = './figs/'\n",
    "version = 'v9'\n",
    "plot_figure5(fig_dir, version, G_KL, \n",
    "                 prior_samples, \n",
    "                 case1_data,\n",
    "                 case2_data,\n",
    "                 case3_data,\n",
    "                 Ns_factor)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "4ff4ac6af9578637e0e623c40bf41129eb04e2c9abec3a9480d43324f3a3fec8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
