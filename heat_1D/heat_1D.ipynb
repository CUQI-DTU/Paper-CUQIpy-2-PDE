{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Not to be included in the paper ###\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import floor\n",
    "import sys\n",
    "import cuqi\n",
    "cuqi.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUQIpy example: 1D Heat problem\n",
    "\n",
    "Here we go through the steps of creating a time dependant PDE-based Bayesian problem within the CUQIpy library. The problem we consider is a one dimensional (1D) ]time-dependent[ [initial-boundary value] heat ]model[ [equaiton] with zero boundary conditions.\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial u(x,t)}{\\partial t} - c^2 \\frac{\\partial^2 u(x,t)}{\\partial x^2}   & = f(x,t), \\;x\\in[0,L],\\; 0\\le t \\le T\\\\\n",
    "u(0,t)= u(L,t)&= 0\\\\\n",
    "u(x,0)&= g(x) \n",
    "\\end{align}\n",
    "\n",
    "\n",
    "where $u(x,t)$ is the temperature and $c^2$ is the thermal diffusivity (assumed to be 1 here). We assume the source term $f$ is zero. The unknown Bayesian parameters (random variable) for this test problem is the initial heat profile $\\theta(x):=g(x)$ [$g(x)$].\n",
    "\n",
    "The data we obtain for this problem is ]the temperature measurements everywhere[ [the measurement of the temperature profile] ]in the domain[ at ]the final[ time $T$. We assume that the measurement error $\\eta$ follows a Gaussian distribution. In a Bayesian setting, we can represent the data as a random variable $y$:\n",
    "\n",
    "\\begin{align}\n",
    "y = \\mathcal{G}(\\theta) + \\eta, \\;\\;\\; \\eta\\sim\\mathcal{N}(0,\\sigma_\\text{noise}^2\\mathbf{I}),\n",
    "\\end{align}\n",
    "\n",
    "where $\\mathcal{G}(\\theta)$ is the forward model that maps the initial condition $\\theta$ to the final time solution $u(x,T)$ via solving the 1D time-dependent heat problem. For this test case, $T=0.01$, $L=1$, relative noise level is $0.01$ [$1\\%$?], and the number of grid nodes for the finite difference discretization is $100$.\n",
    "\n",
    "In the remaining of this section, we create and solve [the inverse heat equation in a Bayesian setting, i.e. constructing the posterior distribution for $\\theta(x)$] ]the Bayesian problem which is the task of inferring the posterior distribution of the initial heat profile $\\theta(x)$[ given [some] observed data $y_\\text{obs}$ [not defined.]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create the PDE problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Not to be included in the paper ###\n",
    "\n",
    "# Prepare PDE form\n",
    "N = 80   # Number of solution nodes\n",
    "L = 1.0  # Length of the domain\n",
    "T = 0.04 # Final time\n",
    "dx = L/(N+1)   # Space step size\n",
    "cfl = 5/11 # The cfl condition to have a stable solution\n",
    "dt_approx = cfl*dx**2 # Defining approximate time step size\n",
    "num_time_steps = int(T/dt_approx)+1 # Number of time steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create the ]building blocks[ [physical and numerical parameters] that we need to define the 1D time-dependant heat ]PDE[ [problem]. ]We choose the number of solution nodes[ [Here,] `N`[is the number of discretization points] (before N=100 and now N=80), ]the domain length[ `L` [is the length of the domain], ]the final time[ `T` [is the length of time integraion], and ]number of time steps[ `num_time_steps` [is the number of time steps] ]to be 80, 1.0, 0.03, 434, respectively[. ]Then[ [In the following,] we define three python objects: a `numpy.ndarray` representing the spatial grid `grid`, a `numpy.ndarray` array representing the time steps `time_steps` and a `numpy.ndarray` representing the discretized diffusion differential operator using centered difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid for the heat model\n",
    "grid = np.linspace(dx, L, N, endpoint=False)\n",
    "\n",
    "# Time steps\n",
    "time_steps = np.linspace(0, T, num_time_steps, endpoint=True)\n",
    "\n",
    "# PDE form (diff_op, IC, time_steps) [centered FD discretization?]\n",
    "Dxx = (np.diag( -2*np.ones(N) ) + np.diag(np.ones(N-1),-1) + np.diag(np.ones(N-1),1))/dx**2 # FD diffusion operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create `cuqi.pde.TimeDependentLinearPDE` object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The details of the PDE problem is encapsulated in a `cuqi.pde.PDE` object. For this time-dependent problem we create `cuqi.pde.TimeDependentLinearPDE` object. This object needs information about the grid `grid`[,] ]and[ the time ]stepping[ [steps] `time_steps` and ]a representation of the PDE at a given time `t`[ [the time sptes `time_steps`]. This representation is a python function that accepts as ]a[ [the] first argument an instance of the ]Bayesian[ parameter, the `initial_condition` here, and the time `t` as a second argument. It returns a tuple of the differential operator at time `t`, the right hand side at time `t` and the initial condition. [As an optional argument,] ]One[ [one] can [also] specify [whether] the time discretization scheme ]to be[ [is] implicit or explicit ]euler[ [Euler] ],[ [.] ]addition to other arguments that are accepted by parent classes `cuqi.pde.LinearPDE` and `cuqi.pde.PDE`.["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PDE_form(initial_condition, t): return (Dxx, np.zeros(N), initial_condition)\n",
    "\n",
    "PDE = cuqi.pde.TimeDependentLinearPDE(\n",
    "    PDE_form, time_steps, grid_sol=grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create the forward model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create ]the[ [a] `cuqipy` forward model. ]In this case we[ [We] create a `cuqi.model.PDEModel` which is a subclass of `cuqi.model.Model`. To initialize an object of this class, we pass a `cuqi.pde.PDE` along with two `cuqi.geometry.Geometry` objects to represent the domain and the range of the forward PDE problem. `cuqi.model.PDEModel` is agnostic to the underlying details of the PDE. It interact with the `PDE` object through the functions `assemble`, `solve`, and `observe`. ]The underlying `PDE` object might be representing, for example, a time-dependent PDE problem discretized using finite difference method or a steady state PDE problem discretized using finite element method.[\n",
    "\n",
    "(Should we explain what assmble, solve and observe are?)\n",
    "\n",
    "The domain geometry represents the domain of the forward problem[.] ],[ [For the heat euqation the domain geometry represents] the function space of the discretized $g(x)$ ($g$ or $\\theta$?) ]in this case[. To impose some regularity on the initial condition $g(x)$, we parametrize it using Karhunen–Loève (KL) expansion ].[ ]This will represent the inferred heat initial profile as a linear combination of sine functions and a constant.[ \n",
    "\n",
    "$$g(x_j) = u(x_j,0) = \\sum_{i=0}^{N-2} \\left(\\frac{1}{(i+1)^\\gamma\\tau}\\right)  \\theta_i \\, \\text{sin}\\left(\\frac{\\pi}{N}(i+1)(j+\\frac{1}{2})\\right) + \\frac{(-1)^j}{2}\\left(\\frac{1}{N^\\gamma\\tau}\\right)  \\theta_{N-1}$$\n",
    "\n",
    "(what is the constant term?)\n",
    "\n",
    "(clash of notation with $\\theta$)\n",
    "\n",
    "    \n",
    "where $x_j$ is the $j^\\text{th}$ grid point (in a regular grid), $j=0, 1, 2, 3, ..., N-1$], $N$ is the number of nodes in the grid[, $\\gamma$ is the decay rate, $\\tau$ is a normalization constant, and $\\theta_i$ are the expansion coefficients. We note that using the KL-expansion parameterization, the Bayesian parameters [becomes] ]are[ the coefficients of expansion $\\theta_i$. We set up the domain geometry as a `cuqi.geometry.KLExpansion` object and pass the arguments `decay_rate=1.7` and `normalizer=12` for the decay rate and the normalization constants, respectively.\n",
    "\n",
    "(maybe instead of normalizer, we should say variance?)\n",
    "\n",
    "The range geometry represents the function space of the observed data, $u(0,T)$ in this case, which can be represented by a `cuqi.geometry.Continuous1D` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cuqi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7f/q5vr5rss51l61764rsmxbvx00000gn/T/ipykernel_36527/2773489388.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Set up geometries for model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdomain_geometry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcuqi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKLExpansion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrange_geometry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcuqi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mContinuous1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Prepare model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cuqi' is not defined"
     ]
    }
   ],
   "source": [
    "# Set up geometries for model\n",
    "domain_geometry = cuqi.geometry.KLExpansion(grid, decay_rate=1.7, normalizer=12)\n",
    "range_geometry = cuqi.geometry.Continuous1D(grid)\n",
    "\n",
    "# Prepare model\n",
    "model = cuqi.model.PDEModel(PDE,range_geometry,domain_geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create the Bayesian model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After constructing the forward model, we want to set up the Bayesian model, i.e. the posterior distribution. In `CUQIpy` we achieve this by creating a joint distribution on the Bayesian parameters $\\theta$ and the data $y$ ($y$ or $y_{\\text{obs}}$?) using the `JointDistribution` class[,] and then[,] condition it on a synthesized data that we create for this test case. The joint distribution is given by:\n",
    "\n",
    "\\begin{align}\n",
    "p(\\theta,y) = p(y|\\theta)p(\\theta)\n",
    "\\end{align}\n",
    "where $p(x)$ is the prior probability density function (PDF) and $p(y|\\theta)$ is the data distribution PDF.\n",
    "\n",
    "We start by defining the prior distribution $p(\\theta)$ as a standard multivariate Gaussian distribution $\\mathcal{N}(\\mathbf{0}, \\mathbf{I})$ using `cuqi.distribution.GaussianCov` class. We pass the keyword argument `geometry=domain_geometry` when initializing this distribution so that the distribution encapsulates the knowledge that the multivariate random variable $\\theta$ represents the expansion coefficient in the KL expansion (<equation_number>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the prior distribution \n",
    "x = cuqi.distribution.GaussianCov(np.zeros(model.domain_dim), 1, geometry=domain_geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now samples from the prior will look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Not to be included in the paper ###\n",
    "for i in range(5):\n",
    "    x.sample().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this test case, we assume that the true initial heat profile is given by the expression\n",
    "\n",
    "\\begin{align}\n",
    "g_\\text{exact}(x) = e^{-2x} \\sin(L-x)\n",
    "\\end{align}\n",
    "\n",
    "We create `cuqi.samples.CUQIarray` object representing this signal and we call it `theta_true`. We apply the forward model on `theta_exact` to obtain what we call exact data `y_exact`, which is the outcome of the forward model that is not corrupted by measurement noise.\n",
    "\n",
    "(isn't calling it ''sample'' a little confusing? )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Not to be included in the paper ###\n",
    "\n",
    "# True parameters that we want to infer\n",
    "x_exact_raw = grid*np.exp(-2*grid)*np.sin(L-grid)\n",
    "x_exact = cuqi.samples.CUQIarray(x_exact_raw, is_par=False, geometry=domain_geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the exact data\n",
    "y_exact = model.forward(x_exact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* explain data distribution (1 lines of code) + how we calculated sigma\n",
    "* explain generating data (1 line of code)\n",
    "\n",
    "We then create the data distribution `y` as a `cuqi.distribution.GaussianCov` object with the mean being the forward model applied to the Bayesian parameter $\\theta$ `model(x)` and covariance matrix given by $\\sigma^2\\mathbf{I}_M$ where $\\sigma= \\frac{0.01}{\\sqrt{N}} ||\\mathcal{G}(g_\\text{exact}(x))||$ and $\\mathbf{I}_M$ is the $M$ dimensional identity matrix. We also equip the data distribution with the range geometry `range_geometry`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Not to be included in the paper ###\n",
    "sigma =1.0/np.sqrt(N)* 0.01*np.linalg.norm(y_exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data distribution \n",
    "y = cuqi.distribution.GaussianCov(model(x), sigma**2*np.eye(model.range_dim), geometry=range_geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An instance of ]the[ [a] noisy data (`data`) can then be ]simply[ generated as a sample of the distribution `y` conditioned on `x=x_exact`. Figure <fig_num> shows the exact solution $g(x)$, and the exact and the noisy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate noisy data\n",
    "data = y(x = x_exact).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Not to be included in the paper ###\n",
    "\n",
    "x_exact.plot()\n",
    "y_exact.plot()\n",
    "data.plot()\n",
    "plt.legend(['exact solution', 'exact data', 'noisy data']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Not to be included in the paper ###\n",
    "\n",
    "#plt.plot(data-y_exact)\n",
    "print(np.linalg.norm(data-y_exact))\n",
    "print(np.linalg.norm(y_exact))\n",
    "print(np.linalg.norm(data-y_exact)/np.linalg.norm(y_exact))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the distributions `x` and `y`, we can create the joint distribution $p(x,y)$. Conditioning the joint distribution on `y=data` gives the posterior distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian model\n",
    "joint_distribution = cuqi.distribution.JointDistribution(x, y)\n",
    "posterior = joint_distribution(y = data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Estimate the Bayesian solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "]Solving the Bayesian problem amounts to characterizing the posterior distribution.[ In `CUQIpy` we use MCMC sampling methods to approximate the posterior and compute its moments. ]For[ [In] this test case[,] we use [the or a] component wise Metropolis Hastings algorithm. [This sampler is called from `cuqi.sampler.CWMH`.] We create ]the[ [a] sampler, which takes the `posterior` as an argument in the initialization, and then generates 4000 samples. The `CWMH` (CWMH is not introduced) method `sample_adapt` (this needs more explanation) adjusts the scale of the algorithm (the step size) to achieve a target acceptance rate of about $0.23$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MySampler = cuqi.sampler.CWMH(posterior)\n",
    "posterior_samples = MySampler.sample_adapt(4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "]We use samples visualization and postprocessing methods to obtain the credible interval.[ [CUQIpy provides postprocessing methods to visualize the posterior] In figure <ci_fig1> we show ]the[ [a credible] ]cridible[ interval computed on the coefficient space then transformed to the function space],[ [.] ]whereas[ [Furthermore,] in Figure <ci_fig2> we transform the samples to the function space first, then compute the credible interval. (very long sentence) The later case can be achieved ]easily[ by applying `plot_ci` on the `Samples` property `funvals`, which ]in turns[ return[s] a `Samples` object which contains the function values of the samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples.plot_ci(95, exact=x_exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples.funvals.plot_ci(95, exact=x_exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples.plot_ci(95, plot_par=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(posterior_samples.compute_ess(), 'o-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples.plot_trace([0,1,2,3,4,5,6,7,8,9,10]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|\n",
    "\n",
    "|\n",
    "\n",
    "|\n",
    "\n",
    "|\n",
    "\n",
    "|\n",
    "\n",
    "|\n",
    "\n",
    "|\n",
    "\n",
    "|\n",
    "\n",
    "|\n",
    "\n",
    "|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "* Partial observation \n",
    "* Change end point to L\n",
    "* Enforce positivity \n",
    "* Change x to theta\n",
    "* Fix the noise level\n",
    "* Try the heavy-side after fixing the noise.\n",
    "* Combine pCN with CWMH (each good at different modes)\n",
    "* Reduce the number of nodes\n",
    "* MAP point \n",
    "* hierarchical model for estimating regularity of the heat problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample using pCN sampler\n",
    "pcn_sampler = cuqi.sampler.pCN(posterior)\n",
    "pcn_samples = pcn_sampler.sample_adapt(40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize/Analyze pCN samples\n",
    "pcn_samples.funvals.plot_ci(100, exact=x_exact)\n",
    "plt.figure()\n",
    "pcn_samples.plot_trace([0,1,2,3,4,5,6,7,8,9,10])\n",
    "plt.figure()\n",
    "pcn_samples.plot_ci(plot_par=True)\n",
    "pcn_samples.compute_ess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create samples object that combines 2 samplers results\n",
    "combined_samples = cuqi.samples.Samples(np.hstack([posterior_samples.samples,pcn_samples.samples]), geometry=domain_geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize/Analyze the combined samples\n",
    "combined_samples.funvals.plot_ci(95, exact=x_exact)\n",
    "plt.figure()\n",
    "combined_samples.plot_ci(plot_par=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize/Analyze the combined samples, cont.\n",
    "posterior_samples.plot_pair([0,1,2,3,4])\n",
    "pcn_samples.plot_pair([0,1,2,3,4])\n",
    "combined_samples.plot_pair([0,1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the MAP point\n",
    "maximizer = cuqi.solver.maximize(posterior.logpdf, np.zeros(N))\n",
    "sol = maximizer.solve()\n",
    "plt.plot(grid, domain_geometry.par2fun(sol[0]))\n",
    "x_exact.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the posterior ci and MAP point\n",
    "posterior_samples.plot_ci(95, exact=x_exact)\n",
    "plt.plot(grid, domain_geometry.par2fun(sol[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that the factor 1/sqrt(N) is required to normalize the error vector.\n",
    "norms = []\n",
    "for i in range(100):\n",
    "    norms.append(np.linalg.norm(np.random.randn(i))/np.sqrt(i))\n",
    "norms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "f83c72a7c5d885a4a7f43561cb77434137f6f5cf21a7418d4732e18616218db3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
