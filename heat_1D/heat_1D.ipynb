{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Not to be included in the paper ###\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import floor\n",
    "import sys\n",
    "import cuqi\n",
    "cuqi.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Not to be included in the paper **\n",
    "$\\newcommand{\\code}[1]{\\texttt{#1}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUQIpy example: 1D Heat problem\n",
    "\n",
    "Here we go through the steps of creating a time dependant PDE-based Bayesian problem within the CUQIpy library. The problem we consider is a one dimensional (1D) initial-boundary value heat equation with zero boundary conditions.\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial u(x,t)}{\\partial t} - c^2 \\frac{\\partial^2 u(x,t)}{\\partial x^2}   & = f(x,t), \\;x\\in[0,L],\\; 0\\le t \\le T\\\\\n",
    "u(0,t)= u(L,t)&= 0\\\\\n",
    "u(x,0)&= g(x) \n",
    "\\end{align}\n",
    "\n",
    "\n",
    "where $u(x,t)$ is the temperature and $c^2$ is the thermal diffusivity (assumed to be 1 here). We assume the source term $f$ is zero. The unknown Bayesian parameters (random variable) for this test problem is the initial heat profile $g(x)$.\n",
    "\n",
    "The data we obtain for this problem is the measurement of the temperature profile in the domain at time $T$. We assume that the measurement error $\\eta$ follows a Gaussian distribution. In a Bayesian setting, we can represent the data as a random variable $y$:\n",
    "\n",
    "\\begin{align}\n",
    "y = \\mathcal{G}(\\theta) + \\eta, \\;\\;\\; \\eta\\sim\\mathcal{N}(0,\\sigma_\\text{noise}^2\\mathbf{I}),\n",
    "\\end{align}\n",
    "\n",
    "where $\\mathcal{G}(\\theta)$ is the forward model that maps the initial condition $\\theta$ to the final time solution $u(x,T)$ via solving the 1D time-dependent heat problem. For this test case, $T=0.01$, $L=1$, relative noise level is $1\\%$, and the number of grid nodes for the finite difference discretization is $100$.\n",
    "\n",
    "In the remaining of this section, we create and solve the inverse heat equation in a Bayesian setting, i.e. constructing the posterior distribution for $\\theta(x)$ given some observed data $y_\\text{obs}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create the PDE problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Not to be included in the paper ###\n",
    "\n",
    "# Prepare PDE form\n",
    "N = 80   # Number of solution nodes\n",
    "L = 1.0  # Length of the domain\n",
    "T = 0.04 # Final time\n",
    "dx = L/(N+1)   # Space step size\n",
    "cfl = 5/11 # The cfl condition to have a stable solution\n",
    "dt_approx = cfl*dx**2 # Defining approximate time step size\n",
    "num_time_steps = int(T/dt_approx)+1 # Number of time steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set the physical and numerical parameters and create the components that we need to define the 1D time-dependant heat problem. We discretize the heat problem on a grid of  $\\code{N=80}$ nodes. We choose the domain length $\\code{L=1}$, and the time $\\code{T=0.04}$. We discretize the time interval $[0,T]$ into $\\code{num\\_time\\_steps=434}$ time steps. In the following, we define three python objects: a $\\code{numpy.ndarray}$ representing the spatial grid $\\code{grid}$, a $\\code{numpy.ndarray}$ array representing the time steps $\\code{time\\_steps}$ and a $\\code{numpy.ndarray}$ representing the discretized diffusion differential operator using centered difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid for the heat model\n",
    "grid = np.linspace(dx, L, N, endpoint=False)\n",
    "\n",
    "# Time steps\n",
    "time_steps = np.linspace(0, T, num_time_steps, endpoint=True)\n",
    "\n",
    "# PDE form (diff_op, IC, time_steps)\n",
    "Dxx = (np.diag( -2*np.ones(N) ) + np.diag(np.ones(N-1),-1) + np.diag(np.ones(N-1),1))/dx**2 # FD diffusion operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create $\\code{cuqi.pde.TimeDependentLinearPDE}$ object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The details of the PDE problem is encapsulated in a $\\code{cuqi.pde.PDE}$ object. For \n",
    "this time-dependent problem we create $\\code{cuqi.pde.TimeDependentLinearPDE}$ object.\n",
    " This object needs information about the grid $\\code{grid}$, the time steps \n",
    "$\\code{time\\_steps}$, and a representation of the PDE $\\code{PDE\\_form}$ at a given time $\\code{t}$.\n",
    "As an optional argument, one can also specify whether the time discretization\n",
    " scheme is implicit or explicit Euler. the user can also provide advanced \n",
    " arguments such as the linear solver to be used.\n",
    "\n",
    "This representation $\\code{PDE\\_form}$ is a python function that accepts as the first\n",
    "argument an instance of the inverse problem parameter, the $\\code{initial\\_condition}$\n",
    "here, and the time $\\code{t}$ as a second argument. It returns a tuple of the \n",
    "differential operator at time $\\code{t}$, the right hand side at time $\\code{t}$ and the\n",
    "initial condition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PDE_form(initial_condition, t): return (Dxx, np.zeros(N), initial_condition)\n",
    "\n",
    "PDE = cuqi.pde.TimeDependentLinearPDE(\n",
    "    PDE_form, time_steps, grid_sol=grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create the forward model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a $\\code{cuqipy}$ forward model. We create a $\\code{cuqi.model.PDEModel}$ which is a subclass of $\\code{cuqi.model.Model}$. To initialize an object of this class, we pass a $\\code{cuqi.pde.PDE}$ along with two $\\code{cuqi.geometry.Geometry}$ objects to represent the domain and the range of the forward PDE problem. $\\code{cuqi.model.PDEModel}$ is agnostic to the underlying details of the PDE. It interact with the $\\code{PDE}$ object through the functions $\\code{assemble}$, $\\code{solve}$, and $\\code{observe}$. \n",
    "\n",
    "The domain geometry represents the domain of the forward problem. For the heat equation the domain geometry represents the function space of the discretized $g(x)$. To impose some regularity on the initial condition $g(x)$, we parametrize it using Karhunen–Loève (KL) expansion  \n",
    "\n",
    "$$g(x_j) = u(x_j,0) = \\sum_{i=0}^{N-2} \\left(\\frac{1}{(i+1)^\\gamma\\tau}\\right)  \\theta_i \\, \\text{sin}\\left(\\frac{\\pi}{N}(i+1)(j+\\frac{1}{2})\\right) + \\frac{(-1)^j}{2}\\left(\\frac{1}{N^\\gamma\\tau}\\right)  \\theta_{N-1},$$\n",
    "\n",
    "    \n",
    "where $x_j$ is the $j^\\text{th}$ grid point (in a regular grid), $j=0, 1, 2, 3, ..., N-1$, $\\gamma$ is the decay rate, $\\tau$ is a normalization constant, and $\\theta_i$ are the expansion coefficients. We note that using the KL-expansion parameterization, the Bayesian parameters becomes the coefficients of expansion $\\theta_i$. We set up the domain geometry as a $\\code{cuqi.geometry.KLExpansion}$ object and pass the arguments $\\code{decay\\_rate=1.7}$ and $\\code{normalizer=12}$ for the decay rate and the normalization constants, respectively.\n",
    "\n",
    "The range geometry represents the function space of the observed data, $u(0,T)$ in this case, which can be represented by a $\\code{cuqi.geometry.Continuous1D}$ object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up geometries for model\n",
    "domain_geometry = cuqi.geometry.KLExpansion(grid, decay_rate=1.7, normalizer=12)\n",
    "range_geometry = cuqi.geometry.Continuous1D(grid)\n",
    "\n",
    "# Prepare model\n",
    "model = cuqi.model.PDEModel(PDE,range_geometry,domain_geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create the Bayesian model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After constructing the forward model, we want to set up the Bayesian model, i.e. the posterior distribution. In $\\code{CUQIpy}$ we achieve this by creating a joint distribution on the Bayesian parameters $\\theta$ and the data $y$ using the $\\code{JointDistribution}$ class, and then, condition it on a synthesized data that we create for this test case. The joint distribution is given by:\n",
    "\n",
    "\\begin{align}\n",
    "p(\\theta,y) = p(y|\\theta)p(\\theta)\n",
    "\\end{align}\n",
    "where $p(x)$ is the prior probability density function (PDF) and $p(y|\\theta)$ is the data distribution PDF.\n",
    "\n",
    "We start by defining the prior distribution $p(\\theta)$ as a standard multivariate Gaussian distribution $\\mathcal{N}(\\mathbf{0}, \\mathbf{I})$ using $\\code{cuqi.distribution.Gaussian}$ class. We pass the keyword argument $\\code{geometry=domain\\_geometry}$ when initializing this distribution so that the distribution encapsulates the knowledge that the multivariate random variable $\\theta$ represents the expansion coefficient in the KL expansion (<equation_number>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the prior distribution \n",
    "x = cuqi.distribution.GaussianCov(np.zeros(model.domain_dim), 1, geometry=domain_geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now samples from the prior will look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Not to be included in the paper ###\n",
    "for i in range(5):\n",
    "    x.sample().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this test case, we assume that the true initial heat profile is given by the expression\n",
    "\n",
    "\\begin{align}\n",
    "g_\\text{exact}(x) = e^{-2x} \\sin(L-x)\n",
    "\\end{align}\n",
    "\n",
    "We create $\\code{cuqi.samples.CUQIarray}$ object representing this signal and we call it $\\code{theta\\_true}$. We apply the forward model on $\\code{theta\\_exact}$ to obtain what we call exact data $\\code{y\\_exact}$, which is the outcome of the forward model that is not corrupted by measurement noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Not to be included in the paper ###\n",
    "\n",
    "# True parameters that we want to infer\n",
    "x_exact_raw = grid*np.exp(-2*grid)*np.sin(L-grid)\n",
    "x_exact = cuqi.samples.CUQIarray(x_exact_raw, is_par=False, geometry=domain_geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the exact data\n",
    "y_exact = model.forward(x_exact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We then create the data distribution $\\code{y}$ as a $\\code{cuqi.distribution.GaussianCov}$ object with the mean being the forward model applied to the Bayesian parameter $\\theta$ $\\code{model(x)}$ and covariance matrix given by $\\sigma^2\\mathbf{I}_M$ where $\\sigma= \\frac{0.01}{\\sqrt{N}} ||\\mathcal{G}(g_\\text{exact}(x))||$ and $\\mathbf{I}_M$ is the $M$ dimensional identity matrix. We also equip the data distribution with the range geometry $\\code{range\\_geometry}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Not to be included in the paper ###\n",
    "sigma =1.0/np.sqrt(N)* 0.01*np.linalg.norm(y_exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data distribution \n",
    "y = cuqi.distribution.GaussianCov(model(x), sigma**2*np.eye(model.range_dim), geometry=range_geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An instance of a noisy data ($\\code{data}$) can then be simply generated as a sample of the distribution $\\code{y}$ conditioned on $\\code{x=x\\_exact}$. Figure <fig_num> shows the exact solution $g(x)$, and the exact and the noisy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate noisy data\n",
    "data = y(x = x_exact).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Not to be included in the paper ###\n",
    "\n",
    "x_exact.plot()\n",
    "y_exact.plot()\n",
    "data.plot()\n",
    "plt.legend(['exact solution', 'exact data', 'noisy data']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Not to be included in the paper ###\n",
    "\n",
    "#plt.plot(data-y_exact)\n",
    "print(np.linalg.norm(data-y_exact))\n",
    "print(np.linalg.norm(y_exact))\n",
    "print(np.linalg.norm(data-y_exact)/np.linalg.norm(y_exact))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the distributions $\\code{x}$ and $\\code{y}$, we can create the joint distribution $p(x,y)$. Conditioning the joint distribution on $\\code{y=data}$ gives the posterior distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian model\n",
    "joint_distribution = cuqi.distribution.JointDistribution(x, y)\n",
    "posterior = joint_distribution(y = data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Estimate the Bayesian solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In $\\code{CUQIpy}$ we use MCMC sampling methods to approximate the posterior and compute its moments. In this test case, we use a component wise Metropolis Hastings (CWMH) algorithm which is implemented in the class $\\code{cuqi.sampler.CWMH}$. We create a sampler, which takes the $\\code{posterior}$ as an argument in the initialization, and then generates 4000 samples. The $\\code{CWMH}$ method $\\code{sample\\_adapt}$ adjusts the step size of the algorithm (the step size) to achieve a target acceptance rate of about $0.23$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MySampler = cuqi.sampler.CWMH(posterior)\n",
    "posterior_samples = MySampler.sample_adapt(4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CUQIpy provides postprocessing methods and visualization methods that we can use to study the posterior samples. In figure <ci_fig1> we show a credible interval computed on the coefficient space then transformed to the function space. Furthermore, in Figure <ci_fig2> we transform the samples to the function space first, then compute the credible interval. The later case can be achieved by applying $\\code{plot\\_ci}$ on the $\\code{Samples}$ property $\\code{funvals}$. This property returns a $\\code{Samples}$ object which contains the function values of the samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples.plot_ci(95, exact=x_exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples.funvals.plot_ci(95, exact=x_exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples.plot_ci(95, plot_par=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(posterior_samples.compute_ess(), 'o-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples.plot_trace([0,1,2,3,4,5,6,7,8,9,10]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|\n",
    "\n",
    "|\n",
    "\n",
    "|\n",
    "\n",
    "|\n",
    "\n",
    "|\n",
    "\n",
    "|\n",
    "\n",
    "|\n",
    "\n",
    "|\n",
    "\n",
    "|\n",
    "\n",
    "|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "* Partial observation \n",
    "* Change end point to L\n",
    "* Enforce positivity \n",
    "* Change x to theta\n",
    "* Fix the noise level\n",
    "* Try the heavy-side after fixing the noise.\n",
    "* Combine pCN with CWMH (each good at different modes)\n",
    "* Reduce the number of nodes\n",
    "* MAP point \n",
    "* hierarchical model for estimating regularity of the heat problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample using pCN sampler\n",
    "pcn_sampler = cuqi.sampler.pCN(posterior)\n",
    "pcn_samples = pcn_sampler.sample_adapt(40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize/Analyze pCN samples\n",
    "pcn_samples.funvals.plot_ci(100, exact=x_exact)\n",
    "plt.figure()\n",
    "pcn_samples.plot_trace([0,1,2,3,4,5,6,7,8,9,10])\n",
    "plt.figure()\n",
    "pcn_samples.plot_ci(plot_par=True)\n",
    "pcn_samples.compute_ess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create samples object that combines 2 samplers results\n",
    "combined_samples = cuqi.samples.Samples(np.hstack([posterior_samples.samples,pcn_samples.samples]), geometry=domain_geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize/Analyze the combined samples\n",
    "combined_samples.funvals.plot_ci(95, exact=x_exact)\n",
    "plt.figure()\n",
    "combined_samples.plot_ci(plot_par=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize/Analyze the combined samples, cont.\n",
    "posterior_samples.plot_pair([0,1,2,3,4])\n",
    "pcn_samples.plot_pair([0,1,2,3,4])\n",
    "combined_samples.plot_pair([0,1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the MAP point\n",
    "maximizer = cuqi.solver.maximize(posterior.logpdf, np.zeros(N))\n",
    "sol = maximizer.solve()\n",
    "plt.plot(grid, domain_geometry.par2fun(sol[0]))\n",
    "x_exact.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the posterior ci and MAP point\n",
    "posterior_samples.plot_ci(95, exact=x_exact)\n",
    "plt.plot(grid, domain_geometry.par2fun(sol[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that the factor 1/sqrt(N) is required to normalize the error vector.\n",
    "norms = []\n",
    "for i in range(100):\n",
    "    norms.append(np.linalg.norm(np.random.randn(i))/np.sqrt(i))\n",
    "norms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "f83c72a7c5d885a4a7f43561cb77434137f6f5cf21a7418d4732e18616218db3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
